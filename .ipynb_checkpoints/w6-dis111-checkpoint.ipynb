{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS3 Discussion: Uncertainty\n",
    "\n",
    "*Thank you to Ian Castro for the notebook*\n",
    "\n",
    "In this notebook, we're going to go over the concepts of uncertainty using some basic examples: a die and coin. \n",
    "\n",
    "First, let's explore the relationship between standard deviation and standard error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the sides of a die\n",
    "dice <- c(1:6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the distribution of sides if we roll a die 100 times\n",
    "hundred_rolls <- sample(dice, 100, replace = TRUE)\n",
    "hist(hundred_rolls, col = \"gray\", breaks = c(0.5:6.5))\n",
    "# Does this look like what you expect? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the standard deviation of our 100 rolls?\n",
    "sd(hundred_rolls)\n",
    "# and the mean of 100 rolls:\n",
    "mean(hundred_rolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Check 1\n",
    "\n",
    "What is the standard error of the `hundred_rolls` sample above?\n",
    "\n",
    "Recall: the definition of standard error is `standard deviation of the sample / square root of the sample size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_error <- sd(hundred_rolls) / sqrt(100)\n",
    "standard_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's go do 100 rolls, 1000 times\n",
    "# and calculate the mean for each 100 rolls\n",
    "\n",
    "sample_means <- array()\n",
    "\n",
    "for(i in c(1:1000)){\n",
    "    new_hundred_rolls <- sample(dice, 100, replace = TRUE)\n",
    "    sample_means[i] <- mean(new_hundred_rolls)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of sample means\n",
    "# What's different about this graph versus the first?\n",
    "hist(sample_means, col = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard error = standard deviation of the sample statistic\n",
    "sd(sample_means)\n",
    "\n",
    "# Compare to your mathematical calculation from earlier:\n",
    "standard_error\n",
    "\n",
    "# Notice the similarity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's think about the idea of p-values.\n",
    "\n",
    "Imagine we have a coin. We flip it 10 times, and get 9 heads out of 10 flips. That's weird, because we thought that the coin is fair, and that 50% of the flips should be heads.\n",
    "\n",
    "So, we want to do an analysis: is the coin fair or biased towards heads? Let's use statistics to learn more about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Check 2:\n",
    "\n",
    "Null: \"The coin is fair and the probability of getting heads or tails is the same. Therefore, if I flipped a coin 10 times, 5 of the flips should be heads, on average.\" \n",
    "\n",
    "What is a reasonable alternative hypothesis? Type your answer into the Google Form. \n",
    "\n",
    "*Hint: what did we observe that was weird? What does that observation suggest about the coin?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type any notes you have here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flipping a fair coin; setting 1 to be heads, 0 to be tails\n",
    "coin <- c(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flipping this coin 10 times, 1000 times\n",
    "# assuming that the coin IS fair:\n",
    "\n",
    "num_heads <- array()\n",
    "\n",
    "for(i in c(1:1000)){\n",
    "    heads <- sample(coin, 10, replace = TRUE)\n",
    "    num_heads[i] <- sum(heads) # finding the number of heads\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(num_heads, breaks = c(0:11), col = \"gray\")\n",
    "abline(v = 9, col = \"red\", lwd = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before we calculate the p-value, what does the histogram above tell us about the hypotheses? Discuss with your neighbor.**\n",
    "\n",
    "Then, take a second to confirm your thoughts by calculating the p-value on your own. \n",
    "\n",
    "*Hint:* `num_heads` is a list of numbers of the potential outcomes of flipping a coin, assuming the coin was fair. More extreme, in this case, means greater than the observed value. You can use a Boolean comparison to calculate this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value: the probability of getting the observed result (9 heads) or something more extreme, under the null hypothesis\n",
    "sum(num_heads >= 9) / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's interpret the data.**\n",
    "\n",
    "What does that p-value mean in context?\n",
    "\n",
    "What does it tell you about the coin we have? Is it fair or unfair? \n",
    "\n",
    "Talk about this for a bit before we discuss as a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your notes here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process of using p-values (and by association, t-scores/standard error) lets us account for the uncertainty caused by random chance (e.g. if we repeated the experiment many times, what are the various potential outcomes that could happen?). \n",
    "\n",
    "In practice, when we work with real data, we'll use the `difference_in_means` function to calculate the effect, t-score, standard error, and p-value. This exercise was simply to show the statistical intuition behind these processes!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
